{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/plippmann/.local/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# LIBRARIES\n",
    "\n",
    "from text_extraction import TextExtractorPixelwise\n",
    "import json\n",
    "import re\n",
    "from typing import List, Optional\n",
    "import numpy as np\n",
    "from Levenshtein import distance as leve_distance\n",
    "import pylcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD ANNOTATIONS\n",
    "\n",
    "f = open('../open-mantra-dataset/annotation.json')\n",
    "\n",
    "annotation_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-01-29 16:53:11.050\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmanga_ocr.ocr\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m13\u001b[0m - \u001b[1mLoading OCR model from kha-white/manga-ocr-base\u001b[0m\n",
      "2024-01-29 16:53:12.817161: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "/home/plippmann/.local/lib/python3.8/site-packages/transformers/models/vit/feature_extraction_vit.py:28: FutureWarning: The class ViTFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use ViTImageProcessor instead.\n",
      "  warnings.warn(\n",
      "\u001b[32m2024-01-29 16:53:15.665\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmanga_ocr.ocr\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m19\u001b[0m - \u001b[1mUsing CUDA\u001b[0m\n",
      "\u001b[32m2024-01-29 16:53:17.347\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmanga_ocr.ocr\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m32\u001b[0m - \u001b[1mOCR ready\u001b[0m\n",
      "Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.\n"
     ]
    }
   ],
   "source": [
    "text_extractor = TextExtractorPixelwise(path_to_model='../Manga-Text-Segmentation/model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_non_alpha(text: str) -> str:\n",
    "    res = ''.join([i for i in text if i.isalpha()])\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_counterpart_levenshtein(line: str, candidates: List[str]) -> Optional[str]:\n",
    "    line = remove_non_alpha(line)\n",
    "    distances = [leve_distance(line, remove_non_alpha(candidate)) for candidate in candidates]\n",
    "    min_ind = np.argmin(distances)\n",
    "\n",
    "    res = candidates[min_ind]\n",
    "    # if distances[min_ind] <= len(line)/10:\n",
    "    #     res = candidates[min_ind]\n",
    "    # else:\n",
    "    #     res = None\n",
    "\n",
    "    return res, (distances[min_ind] if len(line) > 0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_counterpart_lcs(line: str, candidates: List[str]) -> Optional[str]:\n",
    "    sim = pylcs.lcs_string_of_list(line, candidates)\n",
    "    if len(sim) == 0:\n",
    "        return \"\", len(line)\n",
    "    max_ind = np.argmax(sim)\n",
    "\n",
    "    best_candidates_ind = np.flatnonzero(sim == np.max(sim))\n",
    "    best_candidates = [candidates[i] for i in best_candidates_ind]\n",
    "    return find_counterpart_levenshtein(line, best_candidates)\n",
    "\n",
    "    best = candidates[max_ind]\n",
    "    dist = leve_distance(remove_non_alpha(line), remove_non_alpha(best))\n",
    "\n",
    "    return candidates[max_ind], (dist if len(remove_non_alpha(line)) > 0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_acc_concat_lines(gt_line, ocr_line):\n",
    "    gt_line = remove_non_alpha(gt_line)\n",
    "    ocr_line = remove_non_alpha(ocr_line)\n",
    "    if min(len(gt_line),len(ocr_line)) == 0:\n",
    "        return int(len(gt_line) == len(ocr_line))\n",
    "    else:\n",
    "        return pylcs.lcs_sequence_length(gt_line, ocr_line)/min(len(gt_line),len(ocr_line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 20.0 %\n",
      "Progress: 40.0 %\n",
      "Progress: 60.0 %\n",
      "Progress: 80.0 %\n",
      "Progress: 100.0 %\n"
     ]
    }
   ],
   "source": [
    "book_titles = {\n",
    "    \"tojime_no_siora\": 0,\n",
    "    \"balloon_dream\": 1, \n",
    "    \"tencho_isoro\": 2, \n",
    "    \"boureisougi\": 3, \n",
    "    \"rasetugari\": 4, \n",
    "\n",
    "}\n",
    "\n",
    "pages = annotation_data[1]['pages']\n",
    "\n",
    "results = []\n",
    "\n",
    "# NSFW pages return bad request so we have to skip sending those images. \n",
    "skipped_pages = [(0, 10)]\n",
    "\n",
    "for manga_index, manga in enumerate(annotation_data):\n",
    "    for page_index, page in enumerate(manga['pages']):\n",
    "        image_path = \"../open-mantra-dataset/\" + page['image_paths']['ja'] #if (manga_index, page_index) not in skipped_pages else None\n",
    "    \n",
    "        ocr_lines = text_extractor.extract_lines(image_path)\n",
    "        jp_ground_truth = []\n",
    "\n",
    "        for line in page['text']:\n",
    "            jp_ground_truth.append(line['text_ja'])\n",
    "\n",
    "        jp_joined = \"\".join(jp_ground_truth)\n",
    "        ocr_joined = \"\".join(ocr_lines)\n",
    "\n",
    "        results.append((jp_joined, (ocr_joined, score_acc_concat_lines(jp_joined, ocr_joined)), (manga_index, page_index)))\n",
    "       \n",
    "\n",
    "        # translations = get_translation(ocr_lines, image_path)\n",
    "            \n",
    "        # print(\"Ground truth JP lines:\")\n",
    "        # for line in sorted(jp_ground_truth):\n",
    "        #     print(line)\n",
    "\n",
    "        # print(\"\")\n",
    "\n",
    "        # print(\"OCR JP lines:\")\n",
    "        # for line in sorted(ocr_lines):\n",
    "        #     print(line)\n",
    "\n",
    "        # for line in jp_ground_truth:\n",
    "        #     results.append((line, find_counterpart_lcs(line, ocr_lines), (manga_index, page_index)))\n",
    "    \n",
    "    print(f\"Progress: {(manga_index + 1) / len(annotation_data) * 100} %\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JGT: \n",
      "OCR: そして、それはそういうそういうことで、\n",
      "ACC: 0\n",
      "manga: 0, page: 32\n",
      "\n",
      "JGT: 私は「生きている彼女」に会ったことはないですがさぞかし美しいお顔だったのでしょうなぜですかっ!?すずめさんお姉さんは有名な美人女優だったそうですね連日メディアが騒いでいます...私では姉のメイクをするには実力不足ということですかハハそういう訳では\n",
      "OCR: お姉さんは有名な美人女優だったそうですね連日メディアが願いでいますあははっちゃーーー私は「生きている彼女」に会ったことはないですがさぞかし美しいお顔だったのでしょう姉のメイクをするには実力不足ということですかハハそういう訳ではロクへ\n",
      "ACC: 0.6052631578947368\n",
      "manga: 3, page: 5\n",
      "\n",
      "JGT: ねぇ〜\n",
      "OCR: \n",
      "ACC: 0\n",
      "manga: 3, page: 25\n",
      "\n",
      "JGT: ツバメさん\n",
      "OCR: \n",
      "ACC: 0\n",
      "manga: 3, page: 28\n",
      "\n",
      "JGT: 心配無用十年越しの怒りそう容易くはないかっ...かかかっかかっよくぞ...\n",
      "OCR: そしてフンッ心配無用！ッ十年越しの怒り．．．そう容易くはないで、オ\n",
      "ACC: 0.6785714285714286\n",
      "manga: 4, page: 22\n",
      "\n",
      "JGT: ぐっ...\n",
      "OCR: ．．．．．．．．．おおお！！\n",
      "ACC: 0.0\n",
      "manga: 4, page: 31\n",
      "\n",
      "AVG_ACC = 0.9422587385149129\n"
     ]
    }
   ],
   "source": [
    "acc_sum = 0\n",
    "\n",
    "for (jp_gt, (ocr_line, acc), (manga_index, page_index)) in results:\n",
    "    acc_sum += acc\n",
    "    if acc < 0.7:\n",
    "        print(f\"JGT: {jp_gt}\")\n",
    "        print(f\"OCR: {ocr_line}\")\n",
    "        print(f\"ACC: {acc}\")\n",
    "        print(f\"manga: {manga_index}, page: {page_index}\")\n",
    "        print(\"\")\n",
    "\n",
    "print(f\"AVG_ACC = {float(acc_sum/len(results))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JGT: あ?ててっ思ったより窓が高かった...おい...なんだこいつ...シオラッ!?いやぁ夜分遅くにすいません...\n",
      "OCR: いや、それは．．．あ？ブッおい．．なんだこいつ．．．シオラッ！？いやぁ夜分遅くにすいません．．．\n",
      "ACC: 0.7878787878787878\n",
      "manga: 0, page: 21\n",
      "\n",
      "JGT: \n",
      "OCR: そして、それはそういうそういうことで、\n",
      "ACC: 0\n",
      "manga: 0, page: 32\n",
      "\n",
      "JGT: バルーンドリーム朽鷹みつき\n",
      "OCR: ンドリーム朽鷹みつきバルー\n",
      "ACC: 0.7692307692307693\n",
      "manga: 1, page: 2\n",
      "\n",
      "JGT: 死んでるんですよねぇようこそ\n",
      "亡霊葬儀屋さん\n",
      "吉良いと「視える」人間ってヤツでしてえ?亡くなったお姉さんのお化粧を?烏丸葬儀社社長\n",
      "烏丸枢(からすまくるる）　２５歳はい...葬儀依頼人\n",
      "桜野　すずめ　１９歳\n",
      "OCR: 死んでるんですよねぇ視える」人間ってヤツでしてようこそ亡霊葬儀屋さん古いとふぅううんっ亡くなったお姉さんのお化粧を？鳥丸葬儀を社長歳丸。枢（からすまーくるる）２歳の葬儀依頼人桜野すずめ１９歳\n",
      "ACC: 0.7710843373493976\n",
      "manga: 3, page: 3\n",
      "\n",
      "JGT: 私は「生きている彼女」に会ったことはないですがさぞかし美しいお顔だったのでしょうなぜですかっ!?すずめさんお姉さんは有名な美人女優だったそうですね連日メディアが騒いでいます...私では姉のメイクをするには実力不足ということですかハハそういう訳では\n",
      "OCR: お姉さんは有名な美人女優だったそうですね連日メディアが願いでいますあははっちゃーーー私は「生きている彼女」に会ったことはないですがさぞかし美しいお顔だったのでしょう姉のメイクをするには実力不足ということですかハハそういう訳ではロクへ\n",
      "ACC: 0.6052631578947368\n",
      "manga: 3, page: 5\n",
      "\n",
      "JGT: お姉さんの事故後のお顔ご覧になりました?それはそうでしょうねぇ...いえ病院の方からあまり見ない方がいいと言われて...今の桜野ツバメさんは貴女の知っているお顔じゃありませんから\n",
      "OCR: お姉さんの事故後のお顔こんなことがあったのですから、そのままこれはそういうことをしたらしいんだけど．．．あまりませんでしょうかないですよねーっと思いますんご覧になりました？あまり見ない方がいいと言われて．．．ちょっと＊それはそうでしょうねぇ～．．．今の桜野ツバメさんは貴女の知っているお顔じゃありませんから\n",
      "ACC: 0.8292682926829268\n",
      "manga: 3, page: 6\n",
      "\n",
      "JGT: 実際はどうです?ツバメさん迷惑だった?....?「迷惑なんて思っていたら」「私は側になんていてやらない」「妹のアンタが一番よくわかっているでしょう?」ですって\n",
      "OCR: 実際はどうです？私は側になんていてやらない「迷惑なんて思っていたら妹のアンタが一番よくわかっているでしょう？あり\n",
      "ACC: 0.7547169811320755\n",
      "manga: 3, page: 21\n",
      "\n",
      "JGT: ねぇ〜\n",
      "OCR: \n",
      "ACC: 0\n",
      "manga: 3, page: 25\n",
      "\n",
      "JGT: もう目開けていい?うん!今日のメイクはね自信あるんだ!...ぶあはは!下手ッ...頑張ったのにぃ私の専属メイクになれるのはまだまだ先ね私もなれる!?お姉ちゃんのメイク担当!\n",
      "OCR: もう目開けていい？今日のメイクはねあはは！トチッくっ．．．．．．頑張ったのにぃあはははっはは私の専属メイクになれるのはまだまだ先ねお姉ちゃんのメイク担当！\n",
      "ACC: 0.8382352941176471\n",
      "manga: 3, page: 26\n",
      "\n",
      "JGT: ツバメさん\n",
      "OCR: \n",
      "ACC: 0\n",
      "manga: 3, page: 28\n",
      "\n",
      "JGT: にい...さま...やめろ...頼むやめてくれ...あっ...\n",
      "OCR: やめろ！頼むやめてくれ．．．ボック．．．ああボトッあっ．．．\n",
      "ACC: 0.75\n",
      "manga: 4, page: 6\n",
      "\n",
      "JGT: 心配無用十年越しの怒りそう容易くはないかっ...かかかっかかっよくぞ...\n",
      "OCR: そしてフンッ心配無用！ッ十年越しの怒り．．．そう容易くはないで、オ\n",
      "ACC: 0.6785714285714286\n",
      "manga: 4, page: 22\n",
      "\n",
      "JGT: くっおっ...おおおおおおおおーー！！宏也一体どうした!?これはーー璋気が古傷に吸い込まれている!?俺は在藤をーー最高の方法で喰らいたいおのれ...\n",
      "OCR: ゙おっ．．．おぉぉぉおおおぉーー！！どれ！！宏也一体どうした！？これは痛気が古傷に吸い込まれている！？ハーッ俺は在藤を最高の方法で喰らいたいおのれ．．\n",
      "ACC: 0.8360655737704918\n",
      "manga: 4, page: 28\n",
      "\n",
      "JGT: おおおおおおおおおおーー!!そうだ来い次の一太刀だ次の一太刀でーー妄執ごとお前を喰らってやる!!あああああ\n",
      "OCR: おぉおおおねおおぉぉーー！！ダー！！そうね来いで次の一太刀だ！！！！イよ次の一太刀でー妄執ごとーーお前を喰らってやる！！．．．あああキャオ\n",
      "ACC: 0.8367346938775511\n",
      "manga: 4, page: 30\n",
      "\n",
      "JGT: ぐっ...\n",
      "OCR: ．．．．．．．．．おおお！！\n",
      "ACC: 0.0\n",
      "manga: 4, page: 31\n",
      "\n",
      "JGT: あっくれはっ...あ...ああっあああああああああああーー!!\n",
      "OCR: いや、あっくれあ．．．ああっあああぁぁぁああっああーー！！\n",
      "ACC: 0.7391304347826086\n",
      "manga: 4, page: 32\n",
      "\n",
      "JGT: 興醒めだ式神風情が悪あがきを身を挺して主の気を俺から逸らしたかまあいい...さっさと堕ちろ羅刹狩り十年前につけた呪いそう簡単に取れるものではない\n",
      "OCR: 興醒めだ式神風情が悪あがきを身を挺して主の気を俺から逸らしたかまあいい．．．十年前につけた呪い！！そう簡単に取れるものではないさっさと堕ちろ羅刹狩り\n",
      "ACC: 0.8405797101449275\n",
      "manga: 4, page: 33\n",
      "\n",
      "JGT: ーーー！？\n",
      "や、やめろ!はっ...はな、せ...だめだ...\n",
      "OCR: ．．．１０／？や、やめろ！！！．．グッはな、せ．．．ゴボだめだ．．．\n",
      "ACC: 0.7142857142857143\n",
      "manga: 4, page: 36\n",
      "\n",
      "JGT: 呑み込まれーーこの\n",
      "OCR: 呑み込まれーーッグえ・ん\n",
      "ACC: 0.7777777777777778\n",
      "manga: 4, page: 37\n",
      "\n",
      "JGT: ーー呉葉...なんだ\n",
      "OCR: ．．．＂トットッ呉葉．．．なんだ\n",
      "ACC: 0.7142857142857143\n",
      "manga: 4, page: 49\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'dist_sum' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m acc \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0.7\u001b[39m \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(\u001b[38;5;28mlen\u001b[39m(remove_non_alpha(jp_gt)), \u001b[38;5;28mlen\u001b[39m(remove_non_alpha(ocr_line))):\n\u001b[1;32m     16\u001b[0m         completely_wrong \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m        \n\u001b[0;32m---> 18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAVG_ACC = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mfloat\u001b[39m(dist_sum\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mlen\u001b[39m(results))\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtotal_number_of_lines: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(results)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msignificant errors: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msignifictant_errors\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dist_sum' is not defined"
     ]
    }
   ],
   "source": [
    "acc_sum = 0\n",
    "significtant_errors = 0\n",
    "completely_wrong = 0\n",
    "\n",
    "for (jp_gt, (ocr_line, acc), (manga_index, page_index)) in results:\n",
    "    acc_sum += acc\n",
    "    if acc < 0.85:\n",
    "        significtant_errors += 1\n",
    "        print(f\"JGT: {jp_gt}\")\n",
    "        print(f\"OCR: {ocr_line}\")\n",
    "        print(f\"ACC: {acc}\")\n",
    "        print(f\"manga: {manga_index}, page: {page_index}\")\n",
    "        print(\"\")\n",
    "\n",
    "    if acc < 0.7 >= min(len(remove_non_alpha(jp_gt)), len(remove_non_alpha(ocr_line))):\n",
    "        completely_wrong += 1        \n",
    "\n",
    "print(f\"AVG_ACC = {float(acc_sum/len(results))}\")\n",
    "\n",
    "print(f\"total_number_of_lines: {len(results)}\")\n",
    "\n",
    "print(f\"significant errors: {significtant_errors}\")\n",
    "\n",
    "print(f\"completely_wrong: {completely_wrong}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
